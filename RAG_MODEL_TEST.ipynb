{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "30a4b295-ddc6-4a92-bdcd-2589a25b7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import html2text\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from functools import partial\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "import json\n",
    "from pinecone import Pinecone, PodSpec, ServerlessSpec\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pathlib\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140f4882-2a4c-4cc0-a655-0c882f24e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = Path(os.getcwd(), 'data', 'scikit-learn.org', 'stable')\n",
    "\n",
    "def extract_text_from_section(section):\n",
    "    texts = []\n",
    "    for elem in section.children:\n",
    "        if isinstance(elem, NavigableString):\n",
    "            if elem.strip():\n",
    "                texts.append(elem.strip())\n",
    "        elif elem.name == \"section\":\n",
    "            continue\n",
    "        else:\n",
    "            texts.append(elem.get_text().strip())\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "\n",
    "def path_to_uri(path, scheme=\"https://\", domain=\"scikit-learn.org/stable/\"):\n",
    "    return scheme + domain + str(path).split(domain)[-1]\n",
    "\n",
    "\n",
    "def extract_sections(record):\n",
    "    # print(\"RECORD: \", record)\n",
    "    with open(record[\"path\"], \"r\", encoding=\"utf-8\") as html_file:\n",
    "        soup = BeautifulSoup(html_file, \"html.parser\")\n",
    "    sections = soup.find_all(\"section\")\n",
    "    section_list = []\n",
    "    for section in sections:\n",
    "        section_id = section.get(\"id\")\n",
    "        section_text = extract_text_from_section(section)\n",
    "        if section_id:\n",
    "            uri = path_to_uri(path=record[\"path\"])\n",
    "            section_list.append({\"source\": f\"{uri}#{section_id}\", \"text\": section_text})\n",
    "    return section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d3fe45-bc44-4074-819d-8737af963076",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = []\n",
    "for i in DOCS_DIR.rglob(\"*.html\"):\n",
    "    data_chunk+=extract_sections({\"path\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d734af-7b36-495b-9687-8405a95b8737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee2d344-cc64-4278-b3a5-454ac5e76764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER_PARAMETERS\n",
    "\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dbc2b-69fd-44e6-98fb-a206446183b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a699eb7-4c2f-4b6b-8d7f-8b665addfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_section(section, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len)\n",
    "    \n",
    "    chunks = text_splitter.create_documents(\n",
    "        texts=[section[\"text\"]], \n",
    "        metadatas=[{\"source\": section[\"source\"]}])\n",
    "    return [{\"text\": chunk.page_content, \"source\": chunk.metadata[\"source\"]} for chunk in chunks]\n",
    "\n",
    "chunk_function = partial(chunk_section, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3a5cae-45b7-4a05-b38d-ae640e8b8b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 3737/3737 [00:00<00:00, 20793.69it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = list()\n",
    "for section in tqdm(data_chunk):\n",
    "    for chunk in chunk_function(section):\n",
    "        chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01aa043f-9f10-4a4f-87ba-28bce32dcafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all the data chunks: 11030\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of all the data chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0454787d-78bc-4ccd-a637-2b36708e1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "def get_embedding_model(embedding_model_name, model_kwargs, encode_kwargs):\n",
    "    if embedding_model_name == \"text-embedding-ada-002\":\n",
    "        embedding_model = OpenAIEmbeddings(\n",
    "            model=embedding_model_name,\n",
    "            openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    else:\n",
    "        embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name=embedding_model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs)\n",
    "    return embedding_model\n",
    "\n",
    "class EmbedChunks:\n",
    "    def __init__(self, model_name):\n",
    "        self.embedding_model = get_embedding_model(\n",
    "            embedding_model_name=model_name,\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"device\": \"cpu\", \"batch_size\": 100})\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        texts = [chunk[\"text\"] for chunk in batch]\n",
    "        embeddings = self.embedding_model.embed_documents(texts)\n",
    "        for i, chunk in enumerate(batch):\n",
    "            chunk[\"embeddings\"] = embeddings[i]\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "507d3432-08fe-4b60-ad03-12ecb3e5c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_embedding_model(\n",
    "            embedding_model_name=MODEL_NAME,\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"device\": \"cpu\", \"batch_size\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed928fda-ff92-443c-a0c6-e1b9f5a132f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 56/56 [01:12<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "embedder = EmbedChunks(model_name=MODEL_NAME)\n",
    "batch_size = 200\n",
    "embedded_chunks = []\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    batch = chunks[i:i+batch_size]\n",
    "    embedded_batch = embedder(batch)\n",
    "    embedded_chunks.extend(embedded_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fe7c5d-badb-4e93-801b-7c6e59bddd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_json = json.dumps(embedded_chunks, indent=4)\n",
    "\n",
    "file_name = f'{MODEL_NAME}_{CHUNK_SIZE}_{CHUNK_OVERLAP}.json'\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(embedding_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db44c2f0-e86e-4146-9f2d-e65c0beb72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created INDEX: paraphrase-minilm-l6-v2-1000-100 \n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=\"c054a566-8249-4d2b-9846-c1464fa2d0a5\")\n",
    "EMBEDDING_SIZE = len(embedded_chunks[0]['embeddings'])\n",
    "INDEX_NAME = f'{MODEL_NAME}-{CHUNK_SIZE}-{CHUNK_OVERLAP}'.lower()\n",
    "\n",
    "pc.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    dimension=EMBEDDING_SIZE,\n",
    "    metric=\"cosine\",\n",
    "    spec=PodSpec(\n",
    "    environment=\"gcp-starter\"\n",
    "  )\n",
    ") \n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"Created INDEX: {INDEX_NAME} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66e3d23-73f7-4fe1-ba07-4acf6f36b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 111/111 [01:26<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "upsert_data = [\n",
    "    (str(i), chunk[\"embeddings\"], {\"text\": chunk[\"text\"], \"source\": chunk[\"source\"]})\n",
    "    for i, chunk in enumerate(embedded_chunks)\n",
    "]\n",
    "batch_size = 100 \n",
    "for i in tqdm(range(0, len(upsert_data), batch_size)):\n",
    "    batch = upsert_data[i:i+batch_size]\n",
    "    index.upsert(vectors=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71da43fb-a0cf-49ca-ab88-d6178ed6dd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File already exists.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'./results.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    columns = ['Model_name', 'chunk_size', 'chunk_overlap', 'quality_score', 'retrieval_score', 'top_k']\n",
    "\n",
    "    # Create an empty DataFrame with these columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Check if the file exists. If not, create it and write the DataFrame to it\n",
    "    df.to_csv(file_path, index=False)\n",
    "    message = \"File created successfully.\"\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    message = \"File already exists.\"\n",
    "\n",
    "message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e912365-de65-4c84-b69a-2079daab8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/harshan/Desktop/Projects/DocuHelper/File_1.json'\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, 'r') as f:\n",
    "    entries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca96676-d3a2-45de-9735-c25dab421c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model_name, chunk_size, chunk_overlap, quality_score, retrieval_score, top_k]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6ecf133-bbfa-4848-b8ec-062b7b82b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_retrieval_score(model, top_k):\n",
    "    retrieval_score = 0\n",
    "    \n",
    "    for i in tqdm(range(len(entries['question']))):\n",
    "        ques_emd = model.embed_query(entries[\"question\"][i])\n",
    "    \n",
    "        result = index.query(\n",
    "                    vector=ques_emd,\n",
    "                    top_k=top_k,\n",
    "                    include_values=True,\n",
    "                    include_metadata=True)\n",
    "    \n",
    "        for j,row in enumerate(result['matches']):\n",
    "                metadata_src = row['metadata']['source']\n",
    "                actual_src = entries[\"source\"][i]\n",
    "                \n",
    "                if(metadata_src == actual_src):\n",
    "                    retrieval_score += 1\n",
    "                    break\n",
    "    return retrieval_score/len(entries['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "894d3a08-acda-4e54-8231-861d191a67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 405/405 [00:44<00:00,  9.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Hyper-parameter\n",
    "TOP_K = 20\n",
    "\n",
    "ret_score = calc_retrieval_score(model, TOP_K)\n",
    "data_to_add = {\n",
    "    'Model_name': MODEL_NAME,\n",
    "    'chunk_size': CHUNK_SIZE,\n",
    "    'chunk_overlap': CHUNK_OVERLAP,\n",
    "    'quality_score': None,\n",
    "    'retrieval_score': ret_score,\n",
    "    'top_k': TOP_K\n",
    "}\n",
    "data_df = pd.DataFrame([data_to_add])\n",
    "\n",
    "df = pd.concat([df, data_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c1c3edb-a093-4ed7-bce4-55af55eeb21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.508642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model_name chunk_size chunk_overlap quality_score  \\\n",
       "0  paraphrase-MiniLM-L6-v2       1000           100          None   \n",
       "1  paraphrase-MiniLM-L6-v2       1000           100          None   \n",
       "2  paraphrase-MiniLM-L6-v2       1000           100          None   \n",
       "3  paraphrase-MiniLM-L6-v2       1000           100          None   \n",
       "\n",
       "   retrieval_score top_k  \n",
       "0         0.607407    10  \n",
       "1         0.508642     5  \n",
       "2         0.671605    15  \n",
       "3         0.698765    20  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "731b01a4-2cb7-4614-8b87-f54e6a159f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk Size: 300, 500, 750, 1000\n",
    "# Embedding Models: , , albert-base-v2, thenlper/gte-large, Salesforce/SFR-Embedding-Mistral\n",
    "# Done: paraphrase-MiniLM-L6-v2, sentence-transformers/all-MiniLM-L6-v2\n",
    "# Top K: 5, 10, 15, 20\n",
    "# Generator Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "608e18fb-02ef-4e11-b6d4-a9effd382bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0028103808872401714,\n",
       " 0.023341529071331024,\n",
       " -0.02021278813481331,\n",
       " -0.020648889243602753,\n",
       " -0.01504473015666008,\n",
       " 0.0024883304722607136,\n",
       " 0.024049343541264534,\n",
       " 0.003866199404001236,\n",
       " 0.0036074293311685324,\n",
       " 0.01650950312614441,\n",
       " 0.02157127670943737,\n",
       " -0.009122013114392757,\n",
       " -0.009633460082113743,\n",
       " -0.02640335075557232,\n",
       " -0.011911495588719845,\n",
       " 0.01928025111556053,\n",
       " -0.03376557677984238,\n",
       " -0.034735169261693954,\n",
       " -0.026135584339499474,\n",
       " -0.007414830848574638,\n",
       " 0.039037346839904785,\n",
       " 0.01487586461007595,\n",
       " -0.07369969040155411,\n",
       " -0.03379564732313156,\n",
       " -0.025941139087080956,\n",
       " 0.03884253278374672,\n",
       " 0.027977382764220238,\n",
       " 0.0008827262790873647,\n",
       " 0.052573125809431076,\n",
       " 0.05167347192764282,\n",
       " -0.025151550769805908,\n",
       " -0.05276501923799515,\n",
       " 0.015540889464318752,\n",
       " -0.049494534730911255,\n",
       " -0.01282536517828703,\n",
       " -0.022013356909155846,\n",
       " 0.04358859360218048,\n",
       " 0.0027594962157309055,\n",
       " -0.022103294730186462,\n",
       " -0.020906765013933182,\n",
       " -0.01684598997235298,\n",
       " 0.00951335858553648,\n",
       " 0.043720223009586334,\n",
       " -0.04497026652097702,\n",
       " -0.052068695425987244,\n",
       " -0.03719504922628403,\n",
       " -0.02486407198011875,\n",
       " -0.015701118856668472,\n",
       " -0.003083364339545369,\n",
       " -0.00448819063603878,\n",
       " 0.0006754639325663447,\n",
       " 0.0012709818547591567,\n",
       " 0.04683148115873337,\n",
       " -0.017100460827350616,\n",
       " -0.0059050642885267735,\n",
       " 0.03055213950574398,\n",
       " -0.010479995049536228,\n",
       " 0.0009577478631399572,\n",
       " -0.03808780014514923,\n",
       " 0.0026674221735447645,\n",
       " -0.010275240987539291,\n",
       " 0.030984802171587944,\n",
       " 0.021012086421251297,\n",
       " -0.03630191087722778,\n",
       " 0.018388861790299416,\n",
       " 0.014760108664631844,\n",
       " 0.0123218335211277,\n",
       " -0.008613582700490952,\n",
       " 0.014290818013250828,\n",
       " -0.023915395140647888,\n",
       " -0.03656959533691406,\n",
       " 0.04968901723623276,\n",
       " -0.013913335278630257,\n",
       " -0.04876336455345154,\n",
       " -0.02509671449661255,\n",
       " 0.02291608601808548,\n",
       " 0.03141744062304497,\n",
       " 0.026536868885159492,\n",
       " -0.006348375231027603,\n",
       " 0.024916399270296097,\n",
       " 0.03387143090367317,\n",
       " 0.04077719524502754,\n",
       " 0.009122926741838455,\n",
       " 0.019852414727211,\n",
       " -0.041994642466306686,\n",
       " -0.05206013098359108,\n",
       " 0.02638174034655094,\n",
       " 0.005324270576238632,\n",
       " -0.007688360754400492,\n",
       " 0.004221848677843809,\n",
       " -0.010648469440639019,\n",
       " 0.03181106597185135,\n",
       " -0.02167104370892048,\n",
       " -0.0026401623617857695,\n",
       " 0.025598876178264618,\n",
       " 0.04733371362090111,\n",
       " -0.023761605843901634,\n",
       " 0.03067806549370289,\n",
       " 0.012867297045886517,\n",
       " -0.004810503218322992,\n",
       " 0.06561726331710815,\n",
       " 0.05681068077683449,\n",
       " 0.013893356546759605,\n",
       " 0.0442156046628952,\n",
       " -0.03201555833220482,\n",
       " 0.0009560278267599642,\n",
       " 0.020128833130002022,\n",
       " -0.005293597932904959,\n",
       " -0.03209063783288002,\n",
       " -0.035075217485427856,\n",
       " 0.003403492271900177,\n",
       " -0.014497400261461735,\n",
       " 0.024336857721209526,\n",
       " -0.0038889404386281967,\n",
       " -0.008875247091054916,\n",
       " 0.0249740369617939,\n",
       " 0.017621340230107307,\n",
       " 0.044962503015995026,\n",
       " -0.016368268057703972,\n",
       " 0.004360738210380077,\n",
       " 0.020444778725504875,\n",
       " -0.012483893893659115,\n",
       " 0.04720286279916763,\n",
       " -0.03017917275428772,\n",
       " -0.002754989080131054,\n",
       " -0.024684928357601166,\n",
       " -0.027458807453513145,\n",
       " 0.032791659235954285,\n",
       " -0.0017546757590025663,\n",
       " -0.044808968901634216,\n",
       " -0.027397312223911285,\n",
       " -0.012855876237154007,\n",
       " 0.0010478097246959805,\n",
       " 0.03370623663067818,\n",
       " 0.0010993480682373047,\n",
       " 0.003066504606977105,\n",
       " -0.032246481627225876,\n",
       " 0.022410031408071518,\n",
       " 0.037944190204143524,\n",
       " -0.05842705816030502,\n",
       " 0.06296928972005844,\n",
       " 0.022022360935807228,\n",
       " -0.02845441922545433,\n",
       " 0.10735812783241272,\n",
       " -0.0012054428225383162,\n",
       " 0.009809008799493313,\n",
       " -0.0031785645987838507,\n",
       " -0.059114571660757065,\n",
       " -0.021487385034561157,\n",
       " 0.023563098162412643,\n",
       " -0.027559563517570496,\n",
       " 0.0406791977584362,\n",
       " 0.008248758502304554,\n",
       " -0.008362038992345333,\n",
       " -0.023275813087821007,\n",
       " 0.015698524191975594,\n",
       " -0.028678739443421364,\n",
       " 0.05128959193825722,\n",
       " 0.026170039549469948,\n",
       " 0.013154367916285992,\n",
       " -0.005562218371778727,\n",
       " -0.006406277418136597,\n",
       " 0.012682223692536354,\n",
       " 0.03522751107811928,\n",
       " -0.012282434850931168,\n",
       " 0.04395880177617073,\n",
       " -0.018869388848543167,\n",
       " -0.01753418706357479,\n",
       " 0.017183195799589157,\n",
       " -0.04224975407123566,\n",
       " 0.010666228830814362,\n",
       " -0.022502947598695755,\n",
       " 0.003946375567466021,\n",
       " 0.0123594356700778,\n",
       " 0.022188814356923103,\n",
       " 0.043767549097537994,\n",
       " 0.040968380868434906,\n",
       " 0.008789489045739174,\n",
       " 0.026042303070425987,\n",
       " 0.020693637430667877,\n",
       " -0.02440507709980011,\n",
       " -0.001963324612006545,\n",
       " 0.016571540385484695,\n",
       " 0.04610680043697357,\n",
       " 0.007712490390986204,\n",
       " 0.012735560536384583,\n",
       " -0.027498263865709305,\n",
       " -0.010940099135041237,\n",
       " -0.06131890416145325,\n",
       " -0.016323888674378395,\n",
       " -0.02167646400630474,\n",
       " 0.03610174357891083,\n",
       " -0.013371068052947521,\n",
       " 0.021983487531542778,\n",
       " 0.013057242147624493,\n",
       " 0.008810572326183319,\n",
       " -0.013622714206576347,\n",
       " 0.011868039146065712,\n",
       " 0.028012020513415337,\n",
       " -0.046322762966156006,\n",
       " -0.02804686687886715,\n",
       " 0.06576089560985565,\n",
       " 0.002475986024364829,\n",
       " 0.0013840359169989824,\n",
       " 0.023983236402273178,\n",
       " -0.015792762860655785,\n",
       " 0.02196419984102249,\n",
       " 0.04630708694458008,\n",
       " -0.025123106315732002,\n",
       " -0.00010902623762376606,\n",
       " 0.036068394780159,\n",
       " 0.0048354691825807095,\n",
       " -0.039607200771570206,\n",
       " 0.008813515305519104,\n",
       " 0.017106397077441216,\n",
       " -0.03920025750994682,\n",
       " -0.015684761106967926,\n",
       " 0.047188807278871536,\n",
       " -0.009257701225578785,\n",
       " -0.023467838764190674,\n",
       " 0.02845076471567154,\n",
       " 0.001061443705111742,\n",
       " 0.05514772608876228,\n",
       " 0.06445525586605072,\n",
       " 0.006458450108766556,\n",
       " -0.010064676403999329,\n",
       " 0.0080491341650486,\n",
       " 0.0510142520070076,\n",
       " -0.02164793200790882,\n",
       " 0.006167552899569273,\n",
       " 0.0015670370776206255,\n",
       " 0.05789882689714432,\n",
       " 0.002993540605530143,\n",
       " 0.05299869179725647,\n",
       " 0.002329939976334572,\n",
       " 0.025566892698407173,\n",
       " 0.05139618739485741,\n",
       " 0.048518095165491104,\n",
       " 0.0034443025942891836,\n",
       " 0.027751417830586433,\n",
       " 0.0023155556991696358,\n",
       " 0.025119367986917496,\n",
       " -0.0042992690578103065,\n",
       " 0.04668958857655525,\n",
       " -0.003173536155372858,\n",
       " 0.006886348128318787,\n",
       " -0.014063563197851181,\n",
       " -0.0046001942828297615,\n",
       " -0.03420240804553032,\n",
       " 0.021373961120843887,\n",
       " -0.018191786482930183,\n",
       " 0.040429625660181046,\n",
       " 0.01956014148890972,\n",
       " 0.019522598013281822,\n",
       " -0.04019470512866974,\n",
       " -0.02095915377140045,\n",
       " 0.055584318935871124,\n",
       " 0.03965042531490326,\n",
       " -0.025159308686852455,\n",
       " -0.008762852288782597,\n",
       " -0.01103106141090393,\n",
       " 0.011250898241996765,\n",
       " 0.00668641971424222,\n",
       " 0.01845129393041134,\n",
       " 0.004693157970905304,\n",
       " 0.03909354284405708,\n",
       " 0.002215500921010971,\n",
       " -0.0018442528089508414,\n",
       " 0.009226775728166103,\n",
       " -0.055470697581768036,\n",
       " -0.04706619307398796,\n",
       " -0.026907047256827354,\n",
       " -0.05854923650622368,\n",
       " -0.04483839124441147,\n",
       " -0.05100851505994797,\n",
       " 0.001312561915256083,\n",
       " -0.005625316873192787,\n",
       " -0.04901665449142456,\n",
       " -0.0054322355426847935,\n",
       " -0.04434511065483093,\n",
       " 0.008903640322387218,\n",
       " 0.022111743688583374,\n",
       " 0.033763669431209564,\n",
       " 0.02362305484712124,\n",
       " 0.04183538258075714,\n",
       " 0.05347704142332077,\n",
       " -0.03575838357210159,\n",
       " 0.02189555950462818,\n",
       " -0.02886165678501129,\n",
       " 0.021984519436955452,\n",
       " -0.0326935313642025,\n",
       " -0.005251512862741947,\n",
       " -0.021871747449040413,\n",
       " -0.010068295523524284,\n",
       " 0.031467825174331665,\n",
       " -0.026461618021130562,\n",
       " -0.022794082760810852,\n",
       " -0.005405473057180643,\n",
       " -0.029707690700888634,\n",
       " -0.03570179641246796,\n",
       " 0.006557811982929707,\n",
       " -0.01614968478679657,\n",
       " 0.009479081258177757,\n",
       " 0.016394907608628273,\n",
       " -0.04749370738863945,\n",
       " 0.015530006028711796,\n",
       " 0.03538518026471138,\n",
       " -0.021018845960497856,\n",
       " 0.04751845821738243,\n",
       " 0.034020040184259415,\n",
       " -0.07785779982805252,\n",
       " 0.030071521177887917,\n",
       " 0.0002550336066633463,\n",
       " -0.023779189214110374,\n",
       " -0.061015114188194275,\n",
       " 0.027352897450327873,\n",
       " 0.05782178044319153,\n",
       " -0.010251311585307121,\n",
       " -0.050026312470436096,\n",
       " -0.04359408840537071,\n",
       " -0.07278073579072952,\n",
       " -0.0020467762369662523,\n",
       " 0.013717840425670147,\n",
       " -0.017612433061003685,\n",
       " -0.019317684695124626,\n",
       " 0.04138796031475067,\n",
       " -0.007921955548226833,\n",
       " -0.07309700548648834,\n",
       " 0.01863505318760872,\n",
       " -0.055907201021909714,\n",
       " -0.06743891537189484,\n",
       " -0.051474571228027344,\n",
       " -0.021856868639588356,\n",
       " 0.026461923494935036,\n",
       " -0.0007389565580524504,\n",
       " 0.02192622236907482,\n",
       " -0.016397731378674507,\n",
       " -0.01225061621516943,\n",
       " 0.018191084265708923,\n",
       " 0.02266733907163143,\n",
       " 0.026166653260588646,\n",
       " -0.038145534694194794,\n",
       " 0.02925947494804859,\n",
       " 0.00819276925176382,\n",
       " 0.002760291565209627,\n",
       " 0.0062945568934082985,\n",
       " 0.03915110230445862,\n",
       " -0.022717900574207306,\n",
       " -0.003766443347558379,\n",
       " -0.008485873229801655,\n",
       " 0.0050715235993266106,\n",
       " -0.003012147033587098,\n",
       " 0.017375590279698372,\n",
       " 0.01392311416566372,\n",
       " -0.0050583165138959885,\n",
       " 0.023051070049405098,\n",
       " -0.04843294247984886,\n",
       " 0.007597527466714382,\n",
       " 0.051979903131723404,\n",
       " 0.004000742454081774,\n",
       " 0.014756042510271072,\n",
       " -0.007476277183741331,\n",
       " 0.023318298161029816,\n",
       " -0.004850645083934069,\n",
       " 0.005529587157070637,\n",
       " -0.041911784559488297,\n",
       " 0.01742391288280487,\n",
       " 0.026400117203593254,\n",
       " 0.03443770483136177,\n",
       " -0.03075309470295906,\n",
       " 0.057118095457553864,\n",
       " -0.015790684148669243,\n",
       " -0.034000907093286514,\n",
       " 0.042472369968891144,\n",
       " -0.02404961735010147,\n",
       " -0.009114866144955158,\n",
       " 0.056920330971479416,\n",
       " 0.004631130490452051,\n",
       " 0.017288509756326675,\n",
       " -0.049614839255809784,\n",
       " -0.008177426643669605,\n",
       " 0.014332146383821964,\n",
       " 0.03532571718096733,\n",
       " 0.03929157927632332,\n",
       " 0.022016260772943497,\n",
       " 0.03409828245639801,\n",
       " -0.004278203472495079,\n",
       " -0.02534622699022293,\n",
       " -0.036098580807447433,\n",
       " -0.03752841800451279,\n",
       " -0.007324794307351112,\n",
       " -0.03412436321377754,\n",
       " 0.0006616878090426326,\n",
       " 0.011742280796170235,\n",
       " -0.04859015345573425,\n",
       " -0.057353485375642776,\n",
       " 0.02082017995417118,\n",
       " 0.04620150476694107,\n",
       " 0.030031731352210045,\n",
       " -0.007247670087963343,\n",
       " 0.04859378561377525,\n",
       " -0.017045224085450172,\n",
       " 0.036892399191856384,\n",
       " 0.03469589352607727,\n",
       " -0.01598495803773403,\n",
       " 0.006802885327488184,\n",
       " -0.0476185567677021,\n",
       " 0.012381068430840969,\n",
       " 0.048650626093149185,\n",
       " 0.024259936064481735,\n",
       " -0.03730016201734543,\n",
       " 0.010134357027709484,\n",
       " -0.03257942944765091,\n",
       " 0.04878617078065872,\n",
       " -0.006599036511033773,\n",
       " -0.007987864315509796,\n",
       " -0.025424351915717125,\n",
       " -0.0037755868397653103,\n",
       " -0.027475306764245033,\n",
       " 0.007467189338058233,\n",
       " -0.03158480301499367,\n",
       " -0.021229438483715057,\n",
       " -0.03205361217260361,\n",
       " 0.0364280566573143,\n",
       " 0.03533210977911949,\n",
       " -0.04106045886874199,\n",
       " -0.010854491032660007,\n",
       " -0.03676820918917656,\n",
       " 0.008201093412935734,\n",
       " 0.02536408044397831,\n",
       " -0.00807309988886118,\n",
       " -0.036771178245544434,\n",
       " -0.0159758310765028,\n",
       " -0.007765163667500019,\n",
       " -0.04758380725979805,\n",
       " 0.0168905109167099,\n",
       " 0.03805072233080864,\n",
       " 0.02275717258453369,\n",
       " 0.02787633240222931,\n",
       " -0.05034153535962105,\n",
       " -0.0032228240743279457,\n",
       " 0.006485610269010067,\n",
       " 0.013804635964334011,\n",
       " -0.011639310978353024,\n",
       " -0.00011200102744624019,\n",
       " 0.0026802525389939547,\n",
       " -0.016812639310956,\n",
       " 0.04329210892319679,\n",
       " -0.021145153790712357,\n",
       " -0.04207061231136322,\n",
       " 0.049602992832660675,\n",
       " -0.06192538142204285,\n",
       " 0.013009671121835709,\n",
       " -0.02402660623192787,\n",
       " -0.02600032649934292,\n",
       " 0.015651226043701172,\n",
       " 1.200254791910993e-05,\n",
       " -0.00916783232241869,\n",
       " 0.033394746482372284,\n",
       " -0.008850101381540298,\n",
       " -0.004503447096794844,\n",
       " 0.023104868829250336,\n",
       " 0.048604901880025864,\n",
       " -0.049668751657009125,\n",
       " -0.06255459785461426,\n",
       " 0.06198588013648987,\n",
       " -0.012375223450362682,\n",
       " -0.02542993240058422,\n",
       " 0.037486299872398376,\n",
       " 0.021294068545103073,\n",
       " -0.030095431953668594,\n",
       " 0.017964763566851616,\n",
       " 0.03714042529463768,\n",
       " -0.025904467329382896,\n",
       " 0.019994966685771942,\n",
       " -0.05004085600376129,\n",
       " 0.027523331344127655,\n",
       " -0.011978035792708397,\n",
       " -0.007841242477297783,\n",
       " -0.013258769176900387,\n",
       " -0.04671052098274231,\n",
       " 0.04602983966469765,\n",
       " 0.0047720191068947315,\n",
       " -0.01966947875916958,\n",
       " -0.009195048362016678,\n",
       " -0.07678642868995667,\n",
       " -0.017319047823548317,\n",
       " -0.012837442569434643,\n",
       " -0.0470927432179451,\n",
       " 0.03194309398531914,\n",
       " 0.0011115623638033867,\n",
       " -0.016099583357572556,\n",
       " -0.019590111449360847,\n",
       " 0.003905000863596797,\n",
       " -0.017049094662070274,\n",
       " -0.03588887304067612,\n",
       " -0.02735058031976223,\n",
       " -0.007720605470240116,\n",
       " 0.021282795816659927,\n",
       " 0.01238529197871685,\n",
       " -0.006537151522934437,\n",
       " -0.02962060272693634,\n",
       " -0.03731635585427284,\n",
       " 0.03859233111143112,\n",
       " -0.0037827726919203997,\n",
       " -0.027845406904816628,\n",
       " -0.026419201865792274,\n",
       " 0.010585336945950985,\n",
       " -0.020251339301466942,\n",
       " -0.011669972911477089,\n",
       " -0.030451953411102295,\n",
       " -0.0005425437702797353,\n",
       " -0.02339394949376583,\n",
       " -0.002910148585215211,\n",
       " 0.000957957177888602,\n",
       " -0.006394170690327883,\n",
       " -0.008918482810258865,\n",
       " -0.02535843290388584,\n",
       " -0.032210059463977814,\n",
       " 0.06090535596013069,\n",
       " 0.01377059705555439,\n",
       " -0.04134901985526085,\n",
       " -0.05629398301243782,\n",
       " 0.03339221701025963,\n",
       " -0.001298821298405528,\n",
       " 0.04370929300785065,\n",
       " -0.001490086317062378,\n",
       " -0.014817637391388416,\n",
       " -0.031272806227207184,\n",
       " -0.023370057344436646,\n",
       " 0.02342989668250084,\n",
       " -0.04987521097064018,\n",
       " -0.0018069637008011341,\n",
       " -0.07265421003103256,\n",
       " -0.04094983637332916,\n",
       " 0.016178173944354057,\n",
       " 0.020437223836779594,\n",
       " 0.004973169881850481,\n",
       " -0.0423993282020092,\n",
       " 0.006484565790742636,\n",
       " -0.03610515221953392,\n",
       " -0.002470368519425392,\n",
       " -0.0505300872027874,\n",
       " -0.04007565602660179,\n",
       " -0.012388486415147781,\n",
       " -0.020342525094747543,\n",
       " -0.002377461874857545,\n",
       " 0.05848005414009094,\n",
       " -0.01223097275942564,\n",
       " 0.02310982160270214,\n",
       " -0.0018510206136852503,\n",
       " 0.021828630939126015,\n",
       " -0.003970951307564974,\n",
       " -0.005956421140581369,\n",
       " -0.06111440062522888,\n",
       " -0.024331724271178246,\n",
       " 0.012947694398462772,\n",
       " 0.004369052592664957,\n",
       " 0.01137012243270874,\n",
       " 0.019101902842521667,\n",
       " -0.044119495898485184,\n",
       " 0.043435271829366684,\n",
       " -0.04063856974244118,\n",
       " 0.00148686021566391,\n",
       " -0.02212737686932087,\n",
       " -0.012196813710033894,\n",
       " -0.02852235734462738,\n",
       " 0.01882224716246128,\n",
       " 0.03783511742949486,\n",
       " -0.02125738374888897,\n",
       " 0.03369292989373207,\n",
       " -0.011409934610128403,\n",
       " 0.03060806728899479,\n",
       " 0.04309786483645439,\n",
       " 0.057634081691503525,\n",
       " -0.049773819744586945,\n",
       " -0.0275389663875103,\n",
       " -0.04183945804834366,\n",
       " -0.07536162436008453,\n",
       " 0.047318946570158005,\n",
       " -0.0487489327788353,\n",
       " -0.003629827406257391,\n",
       " -0.005883497651666403,\n",
       " -0.008463134057819843,\n",
       " 0.03065035119652748,\n",
       " -0.007111825980246067,\n",
       " 0.03204238414764404,\n",
       " 0.06156257167458534,\n",
       " 0.03808947280049324,\n",
       " 0.002613253891468048,\n",
       " -0.043315596878528595,\n",
       " 0.020186400040984154,\n",
       " 0.03752540424466133,\n",
       " -0.051879625767469406,\n",
       " -0.018048187717795372,\n",
       " -0.03670407086610794,\n",
       " -0.03794005885720253,\n",
       " 0.02276706136763096,\n",
       " -0.025938427075743675,\n",
       " -0.06320060044527054,\n",
       " -0.029804829508066177,\n",
       " 0.004783743992447853,\n",
       " 0.0770968496799469,\n",
       " 0.00026674370747059584,\n",
       " 0.040076807141304016,\n",
       " 0.009388093836605549,\n",
       " -0.04686181992292404,\n",
       " -0.049202289432287216,\n",
       " 0.038747064769268036,\n",
       " 0.03369303420186043,\n",
       " 0.014998029917478561,\n",
       " 0.04977570101618767,\n",
       " -0.012551100924611092,\n",
       " 0.023537924513220787,\n",
       " 0.03433113545179367,\n",
       " 0.0006442276062443852,\n",
       " 0.04118981584906578,\n",
       " -0.029537519440054893,\n",
       " 0.08758232742547989,\n",
       " 0.011540602892637253,\n",
       " -0.041726380586624146,\n",
       " 0.015098221600055695,\n",
       " 0.05049626901745796,\n",
       " -0.09226404875516891,\n",
       " -0.05188605934381485,\n",
       " 0.020326336845755577,\n",
       " 0.01566310226917267,\n",
       " -0.008112953044474125,\n",
       " -0.03361986577510834,\n",
       " 0.010406349785625935,\n",
       " 0.029375065118074417,\n",
       " -0.027744365856051445,\n",
       " -0.0012603329960256815,\n",
       " 0.03605047985911369,\n",
       " -0.01331468764692545,\n",
       " 0.014228397980332375,\n",
       " 0.01113882102072239,\n",
       " 0.03295839950442314,\n",
       " -0.014545612968504429,\n",
       " 0.05677314102649689,\n",
       " 0.023017767816781998,\n",
       " -0.01412196084856987,\n",
       " -0.02317453920841217,\n",
       " -0.006482939701527357,\n",
       " -0.010052242316305637,\n",
       " 0.0015565118519589305,\n",
       " -0.03210298717021942,\n",
       " 0.0675765722990036,\n",
       " -0.017328575253486633,\n",
       " 0.012518394738435745,\n",
       " 0.030081478878855705,\n",
       " -0.012467647902667522,\n",
       " 0.0476410947740078,\n",
       " -0.016043463721871376,\n",
       " 0.01441093161702156,\n",
       " 0.002649940550327301,\n",
       " -0.03694657236337662,\n",
       " -0.09338917583227158,\n",
       " -0.051795102655887604,\n",
       " -0.006837972905486822,\n",
       " -0.01309877634048462,\n",
       " 0.022663818672299385,\n",
       " -0.022825773805379868,\n",
       " 0.0025774298701435328,\n",
       " 0.05015747621655464,\n",
       " 0.032906919717788696,\n",
       " 0.0040696109645068645,\n",
       " -0.08530164510011673,\n",
       " -0.02481406182050705,\n",
       " -0.04437742009758949,\n",
       " -0.04747467115521431,\n",
       " 0.02619110234081745,\n",
       " -0.009447906166315079,\n",
       " -0.0037591164000332355,\n",
       " 0.032335903495550156,\n",
       " 0.015668777748942375,\n",
       " -0.04918685927987099,\n",
       " -0.003305748337879777,\n",
       " 0.00988373626023531,\n",
       " -0.03096720390021801,\n",
       " 0.002987491199746728,\n",
       " -0.04503798112273216,\n",
       " 0.039092838764190674,\n",
       " -0.06937998533248901,\n",
       " -0.03401564061641693,\n",
       " -0.04628771170973778,\n",
       " -0.011919326148927212,\n",
       " 0.01014770194888115,\n",
       " 0.012949220836162567,\n",
       " -0.030766939744353294,\n",
       " 0.013147260993719101,\n",
       " -0.004531487822532654,\n",
       " 0.038450900465250015,\n",
       " -0.008794085122644901,\n",
       " 0.043834663927555084,\n",
       " -0.01952078565955162,\n",
       " -0.029550671577453613,\n",
       " -0.03046688623726368,\n",
       " 0.02450910396873951,\n",
       " -0.03404950350522995,\n",
       " 0.028427723795175552,\n",
       " 0.04720534756779671,\n",
       " -0.029526473954319954,\n",
       " 0.021358858793973923,\n",
       " -0.0015857733087614179,\n",
       " 0.008547989651560783,\n",
       " -0.025152718648314476,\n",
       " 0.039018239825963974,\n",
       " 0.039133548736572266,\n",
       " -0.022893216460943222,\n",
       " -0.04968788102269173,\n",
       " -0.02006417326629162,\n",
       " -0.0010649048490449786,\n",
       " -0.04703744128346443,\n",
       " 0.013980193994939327,\n",
       " -0.0036896688397973776,\n",
       " -0.0004964747349731624,\n",
       " 0.02167840301990509,\n",
       " -0.006787645164877176,\n",
       " -0.020261382684111595,\n",
       " 0.024867558851838112,\n",
       " 0.04491151496767998,\n",
       " -0.013859942555427551,\n",
       " 0.00747981620952487,\n",
       " 0.011273045092821121,\n",
       " 0.002361098537221551,\n",
       " -0.0033534206449985504,\n",
       " 0.00230429763905704,\n",
       " 0.015019511803984642,\n",
       " 0.0210413821041584,\n",
       " -0.02511141076683998,\n",
       " 0.058769822120666504,\n",
       " 0.03417884185910225,\n",
       " -0.017477724701166153,\n",
       " 0.02218921296298504,\n",
       " 0.0013571219751611352,\n",
       " -0.024935327470302582,\n",
       " -0.011447112075984478,\n",
       " 0.008695068769156933,\n",
       " -0.00862184539437294,\n",
       " 0.05192747712135315,\n",
       " 0.024001391604542732,\n",
       " -0.016718892380595207,\n",
       " 0.017237704247236252,\n",
       " -0.01729314588010311,\n",
       " -0.04869311302900314,\n",
       " 0.04042999818921089,\n",
       " -0.03413859382271767,\n",
       " -0.036448895931243896,\n",
       " 0.033003076910972595,\n",
       " -0.05452606454491615,\n",
       " -0.011489448137581348,\n",
       " -0.03070272132754326,\n",
       " -0.010103322565555573,\n",
       " 0.02944345958530903,\n",
       " 0.02625012770295143,\n",
       " -0.015418650582432747,\n",
       " 0.004041580017656088,\n",
       " 0.012497307732701302,\n",
       " 0.03359220176935196,\n",
       " 0.014160777442157269,\n",
       " -0.020255832001566887,\n",
       " -0.025079667568206787,\n",
       " 0.025573933497071266,\n",
       " 0.04417206719517708,\n",
       " -0.03463472053408623,\n",
       " -0.04383459314703941,\n",
       " -0.009766878560185432,\n",
       " 0.041175056248903275,\n",
       " 0.03502586483955383,\n",
       " 0.0018695106264203787,\n",
       " -0.027635011821985245,\n",
       " -0.01736200787127018,\n",
       " 0.024446535855531693,\n",
       " -0.005340836476534605,\n",
       " -0.009786282666027546,\n",
       " 0.02647046186029911,\n",
       " -0.012502391822636127,\n",
       " 0.027053313329815865,\n",
       " -0.04186936095356941,\n",
       " 0.01862257532775402,\n",
       " -0.04489419236779213,\n",
       " 0.02849894016981125,\n",
       " -0.022349858656525612,\n",
       " -0.011612128466367722,\n",
       " -0.009492533281445503,\n",
       " 0.02934742160141468,\n",
       " 0.011535550467669964,\n",
       " -0.006882970687001944,\n",
       " 0.012071151286363602,\n",
       " 0.010127737186849117,\n",
       " 0.05072703957557678,\n",
       " 0.009683094918727875,\n",
       " 0.03258894756436348,\n",
       " 0.01510641723871231,\n",
       " 0.06407660990953445,\n",
       " 0.03253241255879402,\n",
       " 0.051043737679719925,\n",
       " -0.0026016300544142723,\n",
       " 0.03639158979058266,\n",
       " 0.03672803193330765,\n",
       " -0.015319754369556904,\n",
       " -0.020280668511986732,\n",
       " 0.019913572818040848,\n",
       " 0.019826138392090797,\n",
       " 0.02025986835360527,\n",
       " -0.0003656473127193749,\n",
       " -0.03206537663936615,\n",
       " 0.01590394414961338,\n",
       " 0.04468066245317459,\n",
       " 0.004718869458884001,\n",
       " -0.0010768526699393988,\n",
       " -0.006406452041119337,\n",
       " 0.0022041392512619495,\n",
       " 0.0007037695031613111,\n",
       " -0.009820866398513317,\n",
       " 0.05404864624142647,\n",
       " -0.02313566394150257,\n",
       " -0.02031332068145275,\n",
       " 0.02262655831873417,\n",
       " 0.007316997740417719,\n",
       " 0.042381275445222855,\n",
       " 0.030280398204922676,\n",
       " 0.03811749070882797,\n",
       " 0.0371570810675621,\n",
       " 0.005517660640180111,\n",
       " 0.043380726128816605,\n",
       " 0.0014041296672075987,\n",
       " 0.03322361037135124,\n",
       " 0.028210463002324104,\n",
       " -0.00643483642488718,\n",
       " -0.0460381954908371,\n",
       " -0.006317186169326305,\n",
       " -0.017337866127490997,\n",
       " 0.017023921012878418,\n",
       " -0.01562942937016487,\n",
       " -0.014251635409891605,\n",
       " -0.03999117389321327,\n",
       " 0.026030518114566803,\n",
       " 0.006180993281304836,\n",
       " -0.03332635760307312,\n",
       " 0.0280553437769413,\n",
       " -0.037425316870212555,\n",
       " -0.03306642919778824,\n",
       " -0.0488351546227932,\n",
       " 0.04124569147825241,\n",
       " 0.00236262334510684,\n",
       " -0.005612815730273724,\n",
       " 0.047445423901081085,\n",
       " -0.027844248339533806,\n",
       " -0.03120465949177742,\n",
       " 0.05443365126848221,\n",
       " -0.013006869703531265,\n",
       " 0.022292234003543854,\n",
       " 0.011039753444492817,\n",
       " 0.062003325670957565,\n",
       " -0.003863696241751313,\n",
       " 0.042489808052778244,\n",
       " 0.04688331112265587,\n",
       " 5.239088932285085e-05,\n",
       " 0.002709004795178771,\n",
       " 0.028833433985710144,\n",
       " -0.027170052751898766,\n",
       " -0.02717754803597927,\n",
       " -0.0019159972434863448,\n",
       " -0.027877889573574066,\n",
       " 0.01761094108223915,\n",
       " -0.04063833877444267,\n",
       " -0.0003982206399086863,\n",
       " -7.095774344634265e-05,\n",
       " 0.03384176641702652,\n",
       " -0.02793205715715885,\n",
       " -0.02030399814248085,\n",
       " 0.01604670286178589,\n",
       " 0.03827378526329994,\n",
       " -0.01888660341501236,\n",
       " 0.008433849550783634,\n",
       " 0.015287843532860279,\n",
       " 0.023948688060045242,\n",
       " -0.0020097224041819572,\n",
       " -0.0038285839837044477,\n",
       " -0.011554091237485409,\n",
       " -0.06156976521015167,\n",
       " -0.02293132245540619,\n",
       " -0.042160764336586,\n",
       " 0.049505483359098434,\n",
       " -0.011936615221202374,\n",
       " -0.011533488519489765,\n",
       " -0.018327273428440094,\n",
       " -0.06025774031877518,\n",
       " -0.004594484344124794,\n",
       " 0.058784741908311844,\n",
       " -0.012704125605523586,\n",
       " -0.04557314142584801,\n",
       " -0.027782561257481575,\n",
       " 0.07105741649866104,\n",
       " 0.020994829013943672,\n",
       " 0.0183397326618433,\n",
       " -0.016918957233428955,\n",
       " -0.012122581712901592,\n",
       " 0.01917903870344162,\n",
       " 0.05123410373926163,\n",
       " -0.005988112185150385,\n",
       " 0.06110545992851257,\n",
       " 0.02802186831831932,\n",
       " -0.03418967127799988,\n",
       " 0.03152482956647873,\n",
       " 0.0247187502682209,\n",
       " -0.012781140394508839,\n",
       " -0.023822395130991936,\n",
       " -0.04143616184592247,\n",
       " -0.016215205192565918,\n",
       " 0.04878953471779823,\n",
       " -0.04635973274707794,\n",
       " -0.06709349900484085,\n",
       " 0.003215329023078084,\n",
       " 0.01992933824658394,\n",
       " 0.003859181422740221,\n",
       " -0.025537125766277313,\n",
       " -0.040573012083768845,\n",
       " 0.003978412132710218,\n",
       " -0.07468777894973755,\n",
       " -0.0025634916964918375,\n",
       " -0.04748976603150368,\n",
       " -0.01644887775182724,\n",
       " 0.003472409676760435,\n",
       " -0.026994572952389717,\n",
       " -0.013771243393421173,\n",
       " -0.0649472177028656,\n",
       " 0.14566023647785187,\n",
       " 0.08934100717306137,\n",
       " 0.057806942611932755,\n",
       " 0.018146630376577377,\n",
       " 0.030447810888290405,\n",
       " 0.023981695994734764,\n",
       " 0.017567390576004982,\n",
       " -0.033582013100385666,\n",
       " -0.006507739424705505,\n",
       " -0.04831019788980484,\n",
       " 0.009748730808496475,\n",
       " -0.018106380477547646,\n",
       " 0.024291248992085457,\n",
       " 0.022027814760804176,\n",
       " -0.011489051394164562,\n",
       " 0.04693448543548584,\n",
       " -0.061610862612724304,\n",
       " 0.014868737198412418,\n",
       " 0.027432570233941078,\n",
       " -0.004023415967822075,\n",
       " -0.07904518395662308,\n",
       " 0.04671928286552429,\n",
       " 0.0031897067092359066,\n",
       " -3.559761171345599e-05,\n",
       " -0.009160691872239113,\n",
       " 0.027021396905183792,\n",
       " 0.0011454552877694368,\n",
       " -0.06285171210765839,\n",
       " 0.01580565609037876,\n",
       " -0.01638038456439972,\n",
       " 0.016590842977166176,\n",
       " -0.024224231019616127,\n",
       " 0.03238994628190994,\n",
       " -0.008978127501904964,\n",
       " 0.015681955963373184,\n",
       " 0.04784298315644264,\n",
       " -0.013003230094909668,\n",
       " -0.018143929541110992,\n",
       " 0.01574675925076008,\n",
       " 0.03010929562151432,\n",
       " -0.009404805488884449,\n",
       " 0.014566786587238312,\n",
       " 0.022046275436878204,\n",
       " -0.04044000059366226,\n",
       " 0.003909533843398094,\n",
       " 0.0038535858038812876,\n",
       " -0.05291534587740898,\n",
       " 0.014250371605157852,\n",
       " 0.024603264406323433,\n",
       " -0.04709657281637192,\n",
       " 0.06353019177913666,\n",
       " -0.05302302911877632,\n",
       " -0.011257008649408817,\n",
       " -0.019245203584432602,\n",
       " -0.04014275595545769,\n",
       " -0.023493725806474686,\n",
       " -0.00923730619251728,\n",
       " -0.04451483488082886,\n",
       " -0.005127532873302698,\n",
       " 0.006707290653139353,\n",
       " 0.01642414927482605,\n",
       " 0.004831859841942787,\n",
       " -0.027039891108870506,\n",
       " -0.015238389372825623,\n",
       " -0.012836745008826256,\n",
       " 0.00510712806135416,\n",
       " 0.027934685349464417,\n",
       " 0.026245106011629105,\n",
       " 0.009510739706456661,\n",
       " -0.019473819062113762,\n",
       " -0.013016725890338421,\n",
       " ...]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME= 'thenlper/gte-large'\n",
    "model = get_embedding_model(\n",
    "            embedding_model_name=MODEL_NAME,\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"device\": \"cpu\", \"batch_size\": 100})\n",
    "model.embed_query(entries[\"question\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85a23d42-b98d-4cbe-a09f-658a8e40eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=\"c054a566-8249-4d2b-9846-c1464fa2d0a5\")\n",
    "upsert_batch_size = 100\n",
    "batch_size_embedding = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dd2de015-0470-4a3f-b31c-569f37a8e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 300\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "MODEL_NAME= 'thenlper/gte-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40385e-178e-42f3-bbe5-98df1bc14031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fc980cf9-9cb3-4161-a82c-482e3e085a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3737/3737 [00:00<00:00, 9365.65it/s]\n",
      "100%|█████████████████████████████████████████| 353/353 [57:30<00:00,  9.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED INDEX:  gte-large-500-100\n",
      "Created Index:  gte-large-300-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 353/353 [10:10<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "chunk_function = partial(chunk_section, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "chunks = list()\n",
    "for section in tqdm(data_chunk):\n",
    "    for chunk in chunk_function(section):\n",
    "        chunks.append(chunk)\n",
    "\n",
    "model = get_embedding_model(\n",
    "            embedding_model_name=MODEL_NAME,\n",
    "            model_kwargs={\"device\": \"mps\"},\n",
    "            encode_kwargs={\"device\": \"mps\", \"batch_size\": 100})\n",
    "\n",
    "embedder = EmbedChunks(model_name=MODEL_NAME)\n",
    "\n",
    "embedded_chunks = []\n",
    "for i in tqdm(range(0, len(chunks), batch_size_embedding)):\n",
    "    batch = chunks[i:i+batch_size_embedding]\n",
    "    embedded_batch = embedder(batch)\n",
    "    embedded_chunks.extend(embedded_batch)\n",
    "\n",
    "\n",
    "EMBEDDING_SIZE = len(embedded_chunks[0]['embeddings'])\n",
    "INDEX_NAME = f'{MODEL_NAME.split(\"/\")[-1]}-{CHUNK_SIZE}-{CHUNK_OVERLAP}'.lower()\n",
    "\n",
    "INDEX_LIST = pc.list_indexes().names()\n",
    "if INDEX_NAME not in INDEX_LIST:\n",
    "    if(len(INDEX_LIST)>0):\n",
    "        pc.delete_index(INDEX_LIST[0])\n",
    "        print(\"DELETED INDEX: \", INDEX_LIST[0])\n",
    "    pc.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    dimension=EMBEDDING_SIZE,\n",
    "    metric=\"cosine\",\n",
    "    spec=PodSpec(\n",
    "    environment=\"gcp-starter\"))\n",
    "\n",
    "    print(\"Created Index: \", INDEX_NAME)\n",
    "    \n",
    "\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "upsert_data = [\n",
    "    (str(i), chunk[\"embeddings\"], {\"text\": chunk[\"text\"], \"source\": chunk[\"source\"]})\n",
    "    for i, chunk in enumerate(embedded_chunks)\n",
    "]\n",
    " \n",
    "for i in tqdm(range(0, len(upsert_data), upsert_batch_size)):\n",
    "    batch = upsert_data[i:i+upsert_batch_size]\n",
    "    index.upsert(vectors=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c1cf98e1-de94-4579-bc9f-4ea9bcbabddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 405/405 [01:20<00:00,  5.01it/s]\n",
      "100%|█████████████████████████████████████████| 405/405 [01:10<00:00,  5.72it/s]\n",
      "100%|█████████████████████████████████████████| 405/405 [01:15<00:00,  5.36it/s]\n",
      "100%|█████████████████████████████████████████| 405/405 [01:19<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "TOP_K = [5, 10, 15, 20]\n",
    "for k in TOP_K:\n",
    "    ret_score = calc_retrieval_score(model, k)\n",
    "    data_to_add = {\n",
    "        'Model_name': MODEL_NAME,\n",
    "        'chunk_size': CHUNK_SIZE,\n",
    "        'chunk_overlap': CHUNK_OVERLAP,\n",
    "        'quality_score': None,\n",
    "        'retrieval_score': ret_score,\n",
    "        'top_k': k\n",
    "    }\n",
    "    data_df = pd.DataFrame([data_to_add])\n",
    "    \n",
    "    df = pd.concat([df, data_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "875eb571-fc7c-4458-8878-0a160522e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'./results.csv'\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b9bb108d-b056-40de-a84b-8a3414f42c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.508642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.501235</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.656790</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.627160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.120988</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model_name chunk_size chunk_overlap  \\\n",
       "0                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "1                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "2                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "3                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "4                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "5                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "6                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "7                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "8                  paraphrase-MiniLM-L6-v2        300            50   \n",
       "9                  paraphrase-MiniLM-L6-v2        300            50   \n",
       "10                 paraphrase-MiniLM-L6-v2        300            50   \n",
       "11                 paraphrase-MiniLM-L6-v2        300            50   \n",
       "12                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "13                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "14                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "15                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "16  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "17  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "18  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "19  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "20  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "21  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "22  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "23  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "24  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "25  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "26  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "27  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "28  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "29  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "30  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "31  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "32                          albert-base-v2        500           100   \n",
       "33                          albert-base-v2        500           100   \n",
       "34                          albert-base-v2        500           100   \n",
       "35                          albert-base-v2        500           100   \n",
       "36                      thenlper/gte-large       1000           100   \n",
       "37                      thenlper/gte-large       1000           100   \n",
       "38                      thenlper/gte-large       1000           100   \n",
       "39                      thenlper/gte-large       1000           100   \n",
       "40                      thenlper/gte-large        500           100   \n",
       "41                      thenlper/gte-large        500           100   \n",
       "42                      thenlper/gte-large        500           100   \n",
       "43                      thenlper/gte-large        500           100   \n",
       "44                      thenlper/gte-large        300            50   \n",
       "45                      thenlper/gte-large        300            50   \n",
       "46                      thenlper/gte-large        300            50   \n",
       "47                      thenlper/gte-large        300            50   \n",
       "\n",
       "   quality_score  retrieval_score top_k  \n",
       "0           None         0.607407    10  \n",
       "1           None         0.508642     5  \n",
       "2           None         0.671605    15  \n",
       "3           None         0.698765    20  \n",
       "4           None         0.718519    20  \n",
       "5           None         0.520988     5  \n",
       "6           None         0.639506    10  \n",
       "7           None         0.686420    15  \n",
       "8           None         0.496296     5  \n",
       "9           None         0.614815    10  \n",
       "10          None         0.664198    15  \n",
       "11          None         0.708642    20  \n",
       "12          None         0.501235     5  \n",
       "13          None         0.604938    10  \n",
       "14          None         0.656790    15  \n",
       "15          None         0.696296    20  \n",
       "16          None         0.639506     5  \n",
       "17          None         0.735802    10  \n",
       "18          None         0.780247    15  \n",
       "19          None         0.822222    20  \n",
       "20          None         0.627160     5  \n",
       "21          None         0.706173    10  \n",
       "22          None         0.770370    15  \n",
       "23          None         0.809877    20  \n",
       "24          None         0.617284     5  \n",
       "25          None         0.701235    10  \n",
       "26          None         0.750617    15  \n",
       "27          None         0.777778    20  \n",
       "28          None         0.649383     5  \n",
       "29          None         0.723457    10  \n",
       "30          None         0.772840    15  \n",
       "31          None         0.819753    20  \n",
       "32          None         0.064198     5  \n",
       "33          None         0.086420    10  \n",
       "34          None         0.103704    15  \n",
       "35          None         0.120988    20  \n",
       "36          None         0.706173     5  \n",
       "37          None         0.795062    10  \n",
       "38          None         0.834568    15  \n",
       "39          None         0.856790    20  \n",
       "40          None         0.716049     5  \n",
       "41          None         0.800000    10  \n",
       "42          None         0.841975    15  \n",
       "43          None         0.871605    20  \n",
       "44          None         0.683951     5  \n",
       "45          None         0.767901    10  \n",
       "46          None         0.819753    15  \n",
       "47          None         0.844444    20  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46b7cc-2883-497f-830a-2d686085056e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "485c6e7e-f4ba-408f-a7fe-152ade56434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Writing the JSON string to a file\n",
    "file_path = f'{INDEX_NAME}.json'  # Define the path to the file\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(upsert_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ffa6b0b4-667a-4610-a312-801ee84bb45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.656790</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.627160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.508642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>750</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.501235</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase-MiniLM-L6-v2</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.120988</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model_name chunk_size chunk_overlap  \\\n",
       "43                      thenlper/gte-large        500           100   \n",
       "39                      thenlper/gte-large       1000           100   \n",
       "47                      thenlper/gte-large        300            50   \n",
       "42                      thenlper/gte-large        500           100   \n",
       "38                      thenlper/gte-large       1000           100   \n",
       "19  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "31  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "46                      thenlper/gte-large        300            50   \n",
       "23  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "41                      thenlper/gte-large        500           100   \n",
       "37                      thenlper/gte-large       1000           100   \n",
       "18  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "27  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "30  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "22  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "45                      thenlper/gte-large        300            50   \n",
       "26  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "17  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "29  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "4                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "40                      thenlper/gte-large        500           100   \n",
       "11                 paraphrase-MiniLM-L6-v2        300            50   \n",
       "21  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "36                      thenlper/gte-large       1000           100   \n",
       "25  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "3                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "15                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "7                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "44                      thenlper/gte-large        300            50   \n",
       "2                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "10                 paraphrase-MiniLM-L6-v2        300            50   \n",
       "14                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "28  sentence-transformers/all-MiniLM-L6-v2        500           100   \n",
       "6                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "16  sentence-transformers/all-MiniLM-L6-v2        750            50   \n",
       "20  sentence-transformers/all-MiniLM-L6-v2       1000           100   \n",
       "24  sentence-transformers/all-MiniLM-L6-v2        300            50   \n",
       "9                  paraphrase-MiniLM-L6-v2        300            50   \n",
       "0                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "13                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "5                  paraphrase-MiniLM-L6-v2        500           100   \n",
       "1                  paraphrase-MiniLM-L6-v2       1000           100   \n",
       "12                 paraphrase-MiniLM-L6-v2        750            50   \n",
       "8                  paraphrase-MiniLM-L6-v2        300            50   \n",
       "35                          albert-base-v2        500           100   \n",
       "34                          albert-base-v2        500           100   \n",
       "33                          albert-base-v2        500           100   \n",
       "32                          albert-base-v2        500           100   \n",
       "\n",
       "   quality_score  retrieval_score top_k  \n",
       "43          None         0.871605    20  \n",
       "39          None         0.856790    20  \n",
       "47          None         0.844444    20  \n",
       "42          None         0.841975    15  \n",
       "38          None         0.834568    15  \n",
       "19          None         0.822222    20  \n",
       "31          None         0.819753    20  \n",
       "46          None         0.819753    15  \n",
       "23          None         0.809877    20  \n",
       "41          None         0.800000    10  \n",
       "37          None         0.795062    10  \n",
       "18          None         0.780247    15  \n",
       "27          None         0.777778    20  \n",
       "30          None         0.772840    15  \n",
       "22          None         0.770370    15  \n",
       "45          None         0.767901    10  \n",
       "26          None         0.750617    15  \n",
       "17          None         0.735802    10  \n",
       "29          None         0.723457    10  \n",
       "4           None         0.718519    20  \n",
       "40          None         0.716049     5  \n",
       "11          None         0.708642    20  \n",
       "21          None         0.706173    10  \n",
       "36          None         0.706173     5  \n",
       "25          None         0.701235    10  \n",
       "3           None         0.698765    20  \n",
       "15          None         0.696296    20  \n",
       "7           None         0.686420    15  \n",
       "44          None         0.683951     5  \n",
       "2           None         0.671605    15  \n",
       "10          None         0.664198    15  \n",
       "14          None         0.656790    15  \n",
       "28          None         0.649383     5  \n",
       "6           None         0.639506    10  \n",
       "16          None         0.639506     5  \n",
       "20          None         0.627160     5  \n",
       "24          None         0.617284     5  \n",
       "9           None         0.614815    10  \n",
       "0           None         0.607407    10  \n",
       "13          None         0.604938    10  \n",
       "5           None         0.520988     5  \n",
       "1           None         0.508642     5  \n",
       "12          None         0.501235     5  \n",
       "8           None         0.496296     5  \n",
       "35          None         0.120988    20  \n",
       "34          None         0.103704    15  \n",
       "33          None         0.086420    10  \n",
       "32          None         0.064198     5  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='retrieval_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3751b-4cf3-418c-bda1-77f0f2f18cd2",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01989b48-6701-400e-82f7-207836f65c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "876b1fc2-f540-4c8e-95b8-e8a8344c4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= 'thenlper/gte-large'\n",
    "ret_model = get_embedding_model(\n",
    "            embedding_model_name=MODEL_NAME,\n",
    "            model_kwargs={\"device\": \"mps\"},\n",
    "            encode_kwargs={\"device\": \"mps\", \"batch_size\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5b916eab-076f-48be-aa06-d7b81d282c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How to do Linear regression?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f564ac26-bc36-4ce0-8459-fe53507d88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_emd = ret_model.embed_query(question)\n",
    "    \n",
    "result = index.query(\n",
    "            vector=ques_emd,\n",
    "            top_k=5,\n",
    "            include_values=True,\n",
    "            include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3bbf8502-2bb3-49fd-8d58-ea9494a92497",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_results = result.matches\n",
    "context = [item.metadata[\"text\"] for item in context_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "105e579a-2edd-4d90-beef-f573d7c47d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "718bcbeb-f750-4c1b-bad9-350b07f35b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(llm):\n",
    "#     if llm.startswith(\"gpt\"):\n",
    "#         base_url = os.environ[\"OPENAI_API_BASE\"]\n",
    "#         api_key = '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'\n",
    "#     else:\n",
    "#         base_url = os.environ[\"ANYSCALE_API_BASE\"]\n",
    "#         api_key = os.environ[\"ANYSCALE_API_KEY\"]\n",
    "#     client = openai.OpenAI(base_url=base_url, api_key=api_key)\n",
    "    return client\n",
    "\n",
    "\n",
    "def response_stream(chat_completion):\n",
    "    for chunk in chat_completion:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content is not None:\n",
    "            yield content\n",
    "\n",
    "\n",
    "def prepare_response(chat_completion, stream):\n",
    "    if stream:\n",
    "        return response_stream(chat_completion)\n",
    "    else:\n",
    "        return chat_completion.choices[0].message.content\n",
    "\n",
    "def generate_response(\n",
    "    llm, temperature=0.0, stream=True,\n",
    "    system_content=\"\", assistant_content=\"\", user_content=\"\", \n",
    "    max_retries=1, retry_interval=60):\n",
    "    \"\"\"Generate response from an LLM.\"\"\"\n",
    "    retry_count = 0\n",
    "    client = get_client(llm=llm)\n",
    "    messages = [{\"role\": role, \"content\": content} for role, content in [\n",
    "        (\"system\", system_content), \n",
    "        (\"assistant\", assistant_content), \n",
    "        (\"user\", user_content)] if content]\n",
    "    while retry_count <= max_retries:\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                model=llm,\n",
    "                temperature=temperature,\n",
    "                stream=stream,\n",
    "                messages=messages,\n",
    "            )\n",
    "            return prepare_response(chat_completion, stream=stream)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "            time.sleep(retry_interval)  # default is per-minute rate limits\n",
    "            retry_count += 1\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4cbc1d77-348b-4151-8a8f-3fc03ec96354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To perform linear regression, you can follow these steps:\n",
      "1. Create a linear regression object using `linear_model.LinearRegression()`.\n",
      "2. Train the model using the training sets with `regr.fit(diabetes_X_train, diabetes_y_train)`.\n",
      "3. Make predictions using the testing set with `diabetes_y_pred = regr.predict(diabetes_X_test)`."
     ]
    }
   ],
   "source": [
    "query = \"How to do linear regression?\"\n",
    "response = generate_response(\n",
    "    llm=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    stream=True,\n",
    "    system_content=\"Answer the query using the context provided. Be succinct.\",\n",
    "    user_content=f\"query: {query}, context: {context}\")\n",
    "# Stream response\n",
    "for content in response:\n",
    "    print(content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db35715-9d8d-4aa9-80f3-e953d84f3088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ddae06f3-a4b6-48cd-93a5-c6397641a58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "auto-gptq",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-c2d6dc415f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             )\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3025\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m             )\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/quantizers/quantizer_gptq.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mgptq_supports_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto-gptq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.4.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgptq_supports_cpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU is required to quantize or run quantize model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/metadata.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \"\"\"\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/metadata.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \"\"\"\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/metadata.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: auto-gptq"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "\n",
    "MODEL_NAME = \"TheBloke/Llama-2-13b-Chat-GPTQ\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config.max_new_tokens = 1024\n",
    "generation_config.temperature = 0.0001\n",
    "generation_config.top_p = 0.95\n",
    "generation_config.do_sample = True\n",
    "generation_config.repetition_penalty = 1.15\n",
    "\n",
    "text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fb9ef-1902-4d71-9268-dd823bb80bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
